{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Linear model implementation in tensorflow\n",
    "'''\n",
    "import tensorflow as tf\n",
    "from chord2vec.linear_models import data_processing as dp\n",
    "import numpy as np\n",
    "import random\n",
    "import pandas as pd\n",
    "import sys\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_train_merged=pd.read_csv('../../data/song_train_merged_transferkey0425.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>chord</th>\n",
       "      <th>error</th>\n",
       "      <th>rating</th>\n",
       "      <th>tab_href</th>\n",
       "      <th>tab_title</th>\n",
       "      <th>version</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_detector_chord</th>\n",
       "      <th>song_chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>5cada0049fc5af34a460ae05</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/art_...</td>\n",
       "      <td>Art For Arts Sake</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Art For Arts Sake 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...</td>\n",
       "      <td>[N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5cada0049fc5af34a460ae07</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/baro...</td>\n",
       "      <td>Baron Samedi</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Baron Samedi 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...</td>\n",
       "      <td>[A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1                       _id artist  \\\n",
       "0           0             0              28  5cada0049fc5af34a460ae05   10cc   \n",
       "1           1             1              29  5cada0049fc5af34a460ae07   10cc   \n",
       "\n",
       "                                               chord  error rating  \\\n",
       "0  [G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...      0      9   \n",
       "1  [G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...      0      3   \n",
       "\n",
       "                                            tab_href          tab_title  \\\n",
       "0  https://tabs.ultimate-guitar.com/tab/10cc/art_...  Art For Arts Sake   \n",
       "1  https://tabs.ultimate-guitar.com/tab/10cc/baro...       Baron Samedi   \n",
       "\n",
       "  version               song_name  \\\n",
       "0   Ver 1  Art For Arts Sake 10cc   \n",
       "1   Ver 1       Baron Samedi 10cc   \n",
       "\n",
       "                                 song_detector_chord  \\\n",
       "0  [{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...   \n",
       "1  [{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...   \n",
       "\n",
       "                                          song_chord  \n",
       "0  [N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...  \n",
       "1  [A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=song_train_merged.copy()\n",
    "df['song_chord']=df['song_chord'].apply(literal_eval)\n",
    "df['chord']=df['chord'].apply(literal_eval)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A:maj',\n",
       " 'A:min',\n",
       " 'Ab:maj',\n",
       " 'Ab:min',\n",
       " 'B:maj',\n",
       " 'Bb:maj',\n",
       " 'Bb:min',\n",
       " 'C:maj',\n",
       " 'D:maj',\n",
       " 'Db:maj',\n",
       " 'Db:min',\n",
       " 'E:maj',\n",
       " 'E:min',\n",
       " 'Eb:maj',\n",
       " 'Eb:min',\n",
       " 'F:maj',\n",
       " 'F:min',\n",
       " 'G:maj',\n",
       " 'Gb:maj',\n",
       " 'Gb:min',\n",
       " 'N'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#資料集中的所有和絃類別\n",
    "chord_list=[]\n",
    "for row in df.chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "for row in df.song_chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "chord_list=set(chord_list)\n",
    "chord_list\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord2Vec:\n",
    "1.準備好train_data，每一個元素是一個和弦，記錄其onset的index <br>\n",
    "例:以12-vector 做many-hot-encoding，C和弦onset的位置為1,5,8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord_vector = {\n",
    "               \n",
    "        'C:maj':  [0,4,7],\n",
    "        'Db:maj': [1,5,8],\n",
    "        'Db:min': [1,4,8],\n",
    "        'D:maj':  [2,7,9],\n",
    "        'Eb:maj': [3,7,10],\n",
    "        'Eb:min': [3,6,10],\n",
    "        'E:maj':  [4,8,11],\n",
    "        'E:min':  [4,7,11],\n",
    "        'F:maj':  [0,5,9],\n",
    "        'F:min':  [0,4,9],\n",
    "        'Gb:maj': [1,6,10],\n",
    "        'Gb:min': [1,6,9],\n",
    "        'G:maj':  [2,7,11],\n",
    "        'G:min':  [2,7,10],\n",
    "        'Ab:maj': [0,3,8],\n",
    "        'Ab:min': [3,8,11],\n",
    "        'A:maj':  [1,4,9],\n",
    "        'A:min':  [0,4,9],\n",
    "        'Bb:maj': [2,5,10],\n",
    "        'Bb:min': [1,5,10],\n",
    "        'B:maj':  [2,6,11],\n",
    "        'B:min':  [1,6,11]    \n",
    "   \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name=\"JSB_Chorales.pickle\"\n",
    "dataset = pickle.load(open(file_name,'rb'))\n",
    "train_data = dataset['train']\n",
    "test_data=dataset['test']\n",
    " valid_data = dataset['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valid_data = dataset['valid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 229\n",
      "test: 77\n",
      "valid: 76\n"
     ]
    }
   ],
   "source": [
    "print('train:',len(train_data))\n",
    "print('test:',len(test_data))\n",
    "print('valid:',len(valid_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chord_word_data:list,存吉他譜與歌曲的和弦進行，一個和弦是一個字，一首歌曲譜是一篇文章\n",
    "chord_word_data=[]\n",
    "for row in df.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    train.append(row_list)\n",
    "for row in df.song_chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    train.append(row_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40204"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_chords="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(file_name = \"JSB_Chorales.pickle\"):\n",
    "    print('Loading data ...')\n",
    "    train_chords, test_chords , valid_chords = dp.read_data(file_name,1)\n",
    "\n",
    "    train_set = dp.generate_binary_vectors(train_chords)\n",
    "    # input_train, target_train = train_set\n",
    "    test_set = dp.generate_binary_vectors(test_chords)\n",
    "    valid_set = dp.generate_binary_vectors(valid_chords)\n",
    "    # input_valid, target_valid = valid_set\n",
    "\n",
    "    data_size = len(train_set[0])\n",
    "    data_size_valid = len(valid_set[0])\n",
    "    data_size_te = len(test_set[0])\n",
    "\n",
    "    total_batch = int(data_size / batch_size)\n",
    "    total_batch_valid = int(data_size_valid / batch_size)\n",
    "    total_batch_test = int(data_size_te / batch_size)\n",
    "\n",
    "    return train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "file_name='JSB_Chorales.pickle'\n",
    "\n",
    "dataset = pickle.load(open(file_name,'rb'))\n",
    "train_data = dataset['train']\n",
    "valid_data = dataset['valid']\n",
    "test_data = dataset['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "D = 1024 # 1st layer number of features\n",
    "NUM_NOTES = 88 # MNIST data input (img shape: 28*28)\n",
    "\n",
    "# tf Graph input\n",
    "input = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "target = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "\n",
    "# Create model\n",
    "def linear(input, weights):\n",
    "    hidden = tf.matmul( \n",
    "        tf.truediv(\n",
    "            input, \n",
    "            tf.maximum(\n",
    "                1.0,\n",
    "                tf.reduce_sum(\n",
    "                    input, \n",
    "                    1, \n",
    "                    keep_dims=True\n",
    "                )\n",
    "            ) \n",
    "        ) ,\n",
    "        weights['hidden']\n",
    "    ) #+ bias['hidden1']\n",
    "    out_layer = tf.matmul(\n",
    "        hidden,\n",
    "        weights['out'])# + bias['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([NUM_NOTES, D]),name='embedding'),\n",
    "    'out': tf.Variable(tf.random_normal([D, NUM_NOTES]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'hidden': tf.Variable(tf.random_normal([D])),\n",
    "    'out': tf.Variable(tf.random_normal([NUM_NOTES]))\n",
    "}\n",
    "embedding_initial=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# loads the embeddings variable from the tensorflow checkpoint\n",
    "def load_embeddings(checkpoint_path):\n",
    "    with tf.Session() as session:\n",
    "        if checkpoint_path:\n",
    "            saver = tf.train.import_meta_graph(checkpoint_path+'/linear_D1024.ckpt-9.meta')\n",
    "            saver.restore(session, tf.train.latest_checkpoint(checkpoint_path))\n",
    "          \n",
    "            return session.run('embedding:0')\n",
    "def get_batch(data_set,id, stoch=False):\n",
    "    if stoch:\n",
    "        transpose_data_set = list(map(list, zip(*data_set)))\n",
    "        batch = random.sample(transpose_data_set, batch_size)\n",
    "        batch_input,batch_target = list(map(list, zip(*batch)))\n",
    "        return batch_input,batch_target\n",
    "    batch_id = id + 1\n",
    "    input, target = data_set\n",
    "    return input[(batch_id * batch_size - batch_size):(batch_id * batch_size)], target[(batch_id * batch_size - batch_size):(batch_id * batch_size)]\n",
    "\n",
    "\n",
    "def train(file_name,checkpoint_path='save_models/linear/linear_D1024.ckpt',load_model=None,print_train=True, print_test=True):\n",
    "    train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid = load_data(file_name)\n",
    "    data_size = len(train_set[0])\n",
    "\n",
    "    # Construct model\n",
    "    print('Create model ...')\n",
    "    \n",
    "    pred = linear(input, weights)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=target),1))\n",
    "\n",
    "\n",
    "    #optimizer = tf.train.AdamOptimizer(epsilon=1e-01,learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver(tf.all_variables(),max_to_keep=1)\n",
    "    \n",
    "    input_valid, target_valid = valid_set\n",
    "\n",
    "    # Launch the graph\n",
    "    print('Start training ...')\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # checkpoint = False #tf.train.get_checkpoint_state('save_models/linear')\n",
    "        # if checkpoint and tf.gfile.Exists(checkpoint.model_checkpoint_path):\n",
    "        #     print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "        #     saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        #     best_val_loss = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "        \n",
    "        print('初始化tf變數...')\n",
    "        sess.run(init)\n",
    "        best_val_loss = np.inf\n",
    "        embedding_initial=sess.run('embedding:0')\n",
    "        \n",
    "        if  print_test:\n",
    "            # Training cycle\n",
    "            previous_eval_loss = []\n",
    "            best_val_epoch = -1\n",
    "            strikes = 0\n",
    "            print('Start Training cycle...')\n",
    "            for epoch in range(training_epochs):\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(data_size/batch_size)\n",
    "                # Loop over all batches\n",
    "                if epoch %10==0:print('Epoch:',epoch,'total_batch:',total_batch)\n",
    "                    \n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = get_batch(train_set,i)\n",
    "                    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                    _, c, out = sess.run([optimizer, cost, pred], feed_dict={input: batch_x,\n",
    "                                                                 target: batch_y})\n",
    "\n",
    "                    # Compute average loss\n",
    "                    avg_cost += c / total_batch\n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%d' % (epoch+1), \"cost=\", \\\n",
    "                        \"{:.9f}\".format(avg_cost))\n",
    "                c_valid = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "                print(\"Valid error %4f\" % (c_valid))\n",
    "                previous_eval_loss.append(c_valid)\n",
    "                improve_valid = previous_eval_loss[-1] < best_val_loss\n",
    "\n",
    "                if improve_valid:\n",
    "                    best_val_loss = previous_eval_loss[-1]\n",
    "                    best_val_epoch = epoch\n",
    "                    # Save checkpoint.\n",
    "                    saver.save(sess, checkpoint_path,global_step=epoch)\n",
    "                else:\n",
    "                    strikes += 1\n",
    "                if strikes > 3:\n",
    "                    break\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "        input_test, target_test = test_set\n",
    "        c_test = sess.run(cost, feed_dict={input: input_test, target: target_test})\n",
    "\n",
    "\n",
    "        print(\"Test error %.9f\" % (c_test))\n",
    "        print(\"Best validation %.9f\" % (best_val_loss))\n",
    "        \n",
    "        print('訓練完成')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_name = \"JSB_Chorales.pickle\"\n",
    "train(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save_models/linear\\linear_D1024.ckpt-9\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.365500</td>\n",
       "      <td>-1.033551</td>\n",
       "      <td>0.169409</td>\n",
       "      <td>0.199125</td>\n",
       "      <td>-0.305248</td>\n",
       "      <td>1.074390</td>\n",
       "      <td>-1.929135</td>\n",
       "      <td>0.863425</td>\n",
       "      <td>-0.599233</td>\n",
       "      <td>0.376368</td>\n",
       "      <td>...</td>\n",
       "      <td>1.932632</td>\n",
       "      <td>-1.487417</td>\n",
       "      <td>-0.496346</td>\n",
       "      <td>1.064925</td>\n",
       "      <td>-1.386224</td>\n",
       "      <td>-0.158865</td>\n",
       "      <td>0.256144</td>\n",
       "      <td>-1.083152</td>\n",
       "      <td>0.020535</td>\n",
       "      <td>-1.690399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.453182</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.445673</td>\n",
       "      <td>0.604382</td>\n",
       "      <td>2.965792</td>\n",
       "      <td>-1.819667</td>\n",
       "      <td>0.202883</td>\n",
       "      <td>-0.811059</td>\n",
       "      <td>0.575867</td>\n",
       "      <td>2.224984</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.693783</td>\n",
       "      <td>0.643162</td>\n",
       "      <td>0.743194</td>\n",
       "      <td>-0.395555</td>\n",
       "      <td>0.276855</td>\n",
       "      <td>0.371267</td>\n",
       "      <td>0.452080</td>\n",
       "      <td>-1.285439</td>\n",
       "      <td>-0.414469</td>\n",
       "      <td>2.011529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.822459</td>\n",
       "      <td>0.376606</td>\n",
       "      <td>0.576009</td>\n",
       "      <td>0.642293</td>\n",
       "      <td>-1.338516</td>\n",
       "      <td>0.719363</td>\n",
       "      <td>-0.209837</td>\n",
       "      <td>-0.515382</td>\n",
       "      <td>-0.240272</td>\n",
       "      <td>-0.415385</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136402</td>\n",
       "      <td>1.837287</td>\n",
       "      <td>-0.064545</td>\n",
       "      <td>-0.673042</td>\n",
       "      <td>0.146252</td>\n",
       "      <td>-0.661147</td>\n",
       "      <td>-1.024617</td>\n",
       "      <td>1.652037</td>\n",
       "      <td>0.065100</td>\n",
       "      <td>-1.065461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.923263</td>\n",
       "      <td>0.868723</td>\n",
       "      <td>-0.053707</td>\n",
       "      <td>-1.621913</td>\n",
       "      <td>-0.507181</td>\n",
       "      <td>0.290807</td>\n",
       "      <td>-0.624988</td>\n",
       "      <td>0.322791</td>\n",
       "      <td>0.396951</td>\n",
       "      <td>-0.687791</td>\n",
       "      <td>...</td>\n",
       "      <td>1.191208</td>\n",
       "      <td>0.403969</td>\n",
       "      <td>0.654257</td>\n",
       "      <td>0.306069</td>\n",
       "      <td>-0.870324</td>\n",
       "      <td>-1.549945</td>\n",
       "      <td>-0.180073</td>\n",
       "      <td>1.810208</td>\n",
       "      <td>0.415091</td>\n",
       "      <td>-1.366199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.098020</td>\n",
       "      <td>1.065474</td>\n",
       "      <td>0.961783</td>\n",
       "      <td>2.366320</td>\n",
       "      <td>-0.371991</td>\n",
       "      <td>0.408312</td>\n",
       "      <td>0.863407</td>\n",
       "      <td>-0.036362</td>\n",
       "      <td>-0.312408</td>\n",
       "      <td>2.394314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.711154</td>\n",
       "      <td>-1.436705</td>\n",
       "      <td>0.186146</td>\n",
       "      <td>-0.171171</td>\n",
       "      <td>1.681844</td>\n",
       "      <td>-0.297972</td>\n",
       "      <td>-0.351790</td>\n",
       "      <td>-0.996052</td>\n",
       "      <td>-2.426108</td>\n",
       "      <td>-0.936139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.365500 -1.033551  0.169409  0.199125 -0.305248  1.074390 -1.929135   \n",
       "1 -0.453182  0.482937  0.445673  0.604382  2.965792 -1.819667  0.202883   \n",
       "2 -0.822459  0.376606  0.576009  0.642293 -1.338516  0.719363 -0.209837   \n",
       "3 -0.923263  0.868723 -0.053707 -1.621913 -0.507181  0.290807 -0.624988   \n",
       "4  1.098020  1.065474  0.961783  2.366320 -0.371991  0.408312  0.863407   \n",
       "\n",
       "       7         8         9       ...         1014      1015      1016  \\\n",
       "0  0.863425 -0.599233  0.376368    ...     1.932632 -1.487417 -0.496346   \n",
       "1 -0.811059  0.575867  2.224984    ...    -0.693783  0.643162  0.743194   \n",
       "2 -0.515382 -0.240272 -0.415385    ...     0.136402  1.837287 -0.064545   \n",
       "3  0.322791  0.396951 -0.687791    ...     1.191208  0.403969  0.654257   \n",
       "4 -0.036362 -0.312408  2.394314    ...    -0.711154 -1.436705  0.186146   \n",
       "\n",
       "       1017      1018      1019      1020      1021      1022      1023  \n",
       "0  1.064925 -1.386224 -0.158865  0.256144 -1.083152  0.020535 -1.690399  \n",
       "1 -0.395555  0.276855  0.371267  0.452080 -1.285439 -0.414469  2.011529  \n",
       "2 -0.673042  0.146252 -0.661147 -1.024617  1.652037  0.065100 -1.065461  \n",
       "3  0.306069 -0.870324 -1.549945 -0.180073  1.810208  0.415091 -1.366199  \n",
       "4 -0.171171  1.681844 -0.297972 -0.351790 -0.996052 -2.426108 -0.936139  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_trained=load_embeddings('save_models/linear')\n",
    "pd.DataFrame(embeddings_trained).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 208.666666,
   "position": {
    "height": "40px",
    "left": "627px",
    "right": "20px",
    "top": "46px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
