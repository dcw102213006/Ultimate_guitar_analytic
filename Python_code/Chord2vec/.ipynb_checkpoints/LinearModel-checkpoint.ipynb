{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import sys\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "Linear model implementation in tensorflow\n",
    "'''\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from chord2vec.linear_models import data_processing as dp\n",
    "import numpy as np\n",
    "import random\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "import time\n",
    "from ast import literal_eval\n",
    "#from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "會把資料整理成train_chords、test_chords、valid_chords三個lists <br>\n",
    "整理過的話直接跳到 \n",
    "# 儲存train_chords、test_chords、valid_chords\n",
    "此chunk，以製作train_set來練chord_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_train_merged=pd.read_csv('../../data/song_train_merged_transferkey0425.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>chord</th>\n",
       "      <th>error</th>\n",
       "      <th>rating</th>\n",
       "      <th>tab_href</th>\n",
       "      <th>tab_title</th>\n",
       "      <th>version</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_detector_chord</th>\n",
       "      <th>song_chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>5cada0049fc5af34a460ae05</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/art_...</td>\n",
       "      <td>Art For Arts Sake</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Art For Arts Sake 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...</td>\n",
       "      <td>[N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5cada0049fc5af34a460ae07</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/baro...</td>\n",
       "      <td>Baron Samedi</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Baron Samedi 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...</td>\n",
       "      <td>[A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1                       _id artist  \\\n",
       "0           0             0              28  5cada0049fc5af34a460ae05   10cc   \n",
       "1           1             1              29  5cada0049fc5af34a460ae07   10cc   \n",
       "\n",
       "                                               chord  error rating  \\\n",
       "0  [G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...      0      9   \n",
       "1  [G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...      0      3   \n",
       "\n",
       "                                            tab_href          tab_title  \\\n",
       "0  https://tabs.ultimate-guitar.com/tab/10cc/art_...  Art For Arts Sake   \n",
       "1  https://tabs.ultimate-guitar.com/tab/10cc/baro...       Baron Samedi   \n",
       "\n",
       "  version               song_name  \\\n",
       "0   Ver 1  Art For Arts Sake 10cc   \n",
       "1   Ver 1       Baron Samedi 10cc   \n",
       "\n",
       "                                 song_detector_chord  \\\n",
       "0  [{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...   \n",
       "1  [{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...   \n",
       "\n",
       "                                          song_chord  \n",
       "0  [N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...  \n",
       "1  [A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=song_train_merged.copy()\n",
    "df['song_chord']=df['song_chord'].apply(literal_eval)\n",
    "df['chord']=df['chord'].apply(literal_eval)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A:maj',\n",
       " 'A:min',\n",
       " 'Ab:maj',\n",
       " 'Ab:min',\n",
       " 'B:maj',\n",
       " 'Bb:maj',\n",
       " 'Bb:min',\n",
       " 'C:maj',\n",
       " 'D:maj',\n",
       " 'Db:maj',\n",
       " 'Db:min',\n",
       " 'E:maj',\n",
       " 'E:min',\n",
       " 'Eb:maj',\n",
       " 'Eb:min',\n",
       " 'F:maj',\n",
       " 'F:min',\n",
       " 'G:maj',\n",
       " 'Gb:maj',\n",
       " 'Gb:min',\n",
       " 'N'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#資料集中的所有和絃類別\n",
    "chord_list=[]\n",
    "for row in df.chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "for row in df.song_chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "chord_list=set(chord_list)\n",
    "chord_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "662"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del chord_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord2Vec:\n",
    "1.準備好train_data，每一個元素是一個和弦，記錄其onset的index <br>\n",
    "例:以12-vector 做many-hot-encoding，C和弦onset的位置為1,5,8 <br>\n",
    "2.把df的chord(row是每篇吉他譜和弦)欄位與song_chord(吉他譜對應的歌曲做完和弦辨識的欄位)合併成一個欄位<br>\n",
    "以便切train、test、valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chord_vector = {\n",
    "               \n",
    "        'C:maj':  [0,4,7],\n",
    "        'Db:maj': [1,5,8],\n",
    "        'Db:min': [1,4,8],\n",
    "        'D:maj':  [2,7,9],\n",
    "        'Eb:maj': [3,7,10],\n",
    "        'Eb:min': [3,6,10],\n",
    "        'E:maj':  [4,8,11],\n",
    "        'E:min':  [4,7,11],\n",
    "        'F:maj':  [0,5,9],\n",
    "        'F:min':  [0,4,9],\n",
    "        'Gb:maj': [1,6,10],\n",
    "        'Gb:min': [1,6,9],\n",
    "        'G:maj':  [2,7,11],\n",
    "        'G:min':  [2,7,10],\n",
    "        'Ab:maj': [0,3,8],\n",
    "        'Ab:min': [3,8,11],\n",
    "        'A:maj':  [1,4,9],\n",
    "        'A:min':  [0,4,9],\n",
    "        'Bb:maj': [2,5,10],\n",
    "        'Bb:min': [1,5,10],\n",
    "        'B:maj':  [2,6,11],\n",
    "        'B:min':  [1,6,11]    \n",
    "   \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用chord2vec_df這張大df切train、test、valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bb:maj, Bb:maj, C:maj, C:maj, Bb:maj, Bb:maj,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chord\n",
       "0  [G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...\n",
       "1  [N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...\n",
       "2  [G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...\n",
       "3  [A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...\n",
       "4  [Bb:maj, Bb:maj, C:maj, C:maj, Bb:maj, Bb:maj,..."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord2vec_df=df[['chord','song_chord']].stack().reset_index()\n",
    "chord2vec_df[0]\n",
    "chord2vec_df=pd.DataFrame({'chord':chord2vec_df[0]})\n",
    "chord2vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 28142\n",
      "test: 6031\n",
      "valid: 6031\n"
     ]
    }
   ],
   "source": [
    "chord2vec_df_train, chord2vec_df_test = train_test_split(chord2vec_df, test_size=0.3)\n",
    "chord2vec_df_test,chord2vec_df_valid=train_test_split(chord2vec_df_test, test_size=0.5)\n",
    "\n",
    "print('train:',len(chord2vec_df_train))\n",
    "print('test:',len(chord2vec_df_test))\n",
    "print('valid:',len(chord2vec_df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#chord_word_data:list,存吉他譜與歌曲的和弦進行，一個和弦是一個字，一首歌曲譜是一篇文章\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "valid_data=[]\n",
    "for row in chord2vec_df_train.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    train_data.append(row_list)\n",
    "for row in chord2vec_df_test.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    test_data.append(row_list)\n",
    "for row in chord2vec_df_valid.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    valid_data.append(row_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord2Vec需要每個字(和弦)的上下文序列作為訓練資料 \n",
    "使用dp.make_chord_context(train_data,test_data,valid_data,1)幫和弦配對上下文 <br>\n",
    "使用prepare_training_data(train_chords,test_chords,valid_chords)把train_set，test_set,valid_set做好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.547751665115356"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#需要1~2分鐘\n",
    "start = time.time()\n",
    "train_chords, test_chords , valid_chords = dp.make_chord_context(train_data,test_data,valid_data,1)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#沒用到的變數先刪掉  節省記憶體\n",
    "del chord2vec_df_train,chord2vec_df_test,chord2vec_df_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "388"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del chord2vec_df,df,row,row_list,song_train_merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del   train_data,test_data,valid_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存train_chords、test_chords、valid_chords\n",
    "train_chords已經做完context配對  <br>\n",
    "接下來要製作train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# out = open(\"LinearModel_data/train_chords.pkl\",\"wb\")\n",
    "# pickle.dump(train_chords, out)\n",
    "# out = open(\"LinearModel_data/test_chords.pkl\",\"wb\")\n",
    "# pickle.dump(test_chords, out)\n",
    "# out = open(\"LinearModel_data/valid_chords.pkl\",\"wb\")\n",
    "# pickle.dump(valid_chords, out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('LinearModel_data/train_chords.pkl', 'rb') as pickle_load:\n",
    "    train_chords = pickle.load(pickle_load)\n",
    "with open('LinearModel_data/test_chords.pkl', 'rb') as pickle_load:\n",
    "    test_chords = pickle.load(pickle_load)\n",
    "with open('LinearModel_data/valid_chords.pkl', 'rb') as pickle_load:\n",
    "    valid_chords = pickle.load(pickle_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(train_chords,test_chords,valid_chords):\n",
    "    print('Loading data ...')\n",
    " \n",
    "    train_set = dp.generate_binary_vectors(train_chords)\n",
    "    # input_train, target_train = train_set\n",
    "    del  train_chords\n",
    "    gc.collect()\n",
    "    test_set = dp.generate_binary_vectors(test_chords)\n",
    "    del  test_chords\n",
    "    gc.collect()\n",
    "    valid_set = dp.generate_binary_vectors(valid_chords)\n",
    "    del  valid_chords\n",
    "    gc.collect()\n",
    "    # input_valid, target_valid = valid_set\n",
    "    \n",
    "    data_size = len(train_set[0])\n",
    "    data_size_valid = len(valid_set[0])\n",
    "    data_size_te = len(test_set[0])\n",
    "\n",
    "    total_batch = int(data_size / batch_size)\n",
    "    total_batch_valid = int(data_size_valid / batch_size)\n",
    "    total_batch_test = int(data_size_te / batch_size)\n",
    "\n",
    "    return train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 200\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "D = 500 # 1st layer number of features\n",
    "NUM_NOTES = 12 #nums of Vocab\n",
    "\n",
    "# tf Graph input\n",
    "input = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "target = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "\n",
    "# Create model\n",
    "def linear(input, weights):\n",
    "    hidden = tf.matmul( \n",
    "        tf.truediv(\n",
    "            input, \n",
    "            tf.maximum(\n",
    "                1.0,\n",
    "                tf.reduce_sum(\n",
    "                    input, \n",
    "                    1, \n",
    "                    keep_dims=True\n",
    "                )\n",
    "            ) \n",
    "        ) ,\n",
    "        weights['hidden']\n",
    "    ) #+ bias['hidden1']\n",
    "    out_layer = tf.matmul(\n",
    "        hidden,\n",
    "        weights['out'])# + bias['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([NUM_NOTES, D]),name='embedding'),\n",
    "    'out': tf.Variable(tf.random_normal([D, NUM_NOTES]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'hidden': tf.Variable(tf.random_normal([D])),\n",
    "    'out': tf.Variable(tf.random_normal([NUM_NOTES]))\n",
    "}\n",
    "embedding_initial=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# loads the embeddings variable from the tensorflow checkpoint\n",
    "def load_embeddings(checkpoint_path):\n",
    "    with tf.Session() as session:\n",
    "        if checkpoint_path:\n",
    "            saver = tf.train.import_meta_graph(checkpoint_path+'/linear_D1024.ckpt-6.meta')\n",
    "            saver.restore(session, tf.train.latest_checkpoint(checkpoint_path))\n",
    "          \n",
    "            return session.run('embedding:0')\n",
    "def get_batch(data_set,id, stoch=False):\n",
    "    if stoch:\n",
    "        transpose_data_set = list(map(list, zip(*data_set)))\n",
    "        batch = random.sample(transpose_data_set, batch_size)\n",
    "        batch_input,batch_target = list(map(list, zip(*batch)))\n",
    "        return batch_input,batch_target\n",
    "    batch_id = id + 1\n",
    "    input, target = data_set\n",
    "    return input[(batch_id * batch_size - batch_size):(batch_id * batch_size)], target[(batch_id * batch_size - batch_size):(batch_id * batch_size)]\n",
    "\n",
    "\n",
    "def train(checkpoint_path='save_models/linear/0507/linear_D1024.ckpt',load_model=None,print_train=True, print_test=True):\n",
    "    train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid = prepare_training_data(train_chords,test_chords,valid_chords)\n",
    "    data_size = len(train_set[0])\n",
    "\n",
    "    # Construct model\n",
    "    print('Create model ...')\n",
    "    \n",
    "    pred = linear(input, weights)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=target),1))\n",
    "\n",
    "\n",
    "    #optimizer = tf.train.AdamOptimizer(epsilon=1e-01,learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver(tf.all_variables(),max_to_keep=1)\n",
    "    \n",
    "    input_valid, target_valid = valid_set\n",
    "\n",
    "    # Launch the graph\n",
    "    print('Start training ...')\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # checkpoint = False #tf.train.get_checkpoint_state('save_models/linear')\n",
    "        # if checkpoint and tf.gfile.Exists(checkpoint.model_checkpoint_path):\n",
    "        #     print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "        #     saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        #     best_val_loss = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "        \n",
    "        print('初始化tf變數...')\n",
    "        sess.run(init)\n",
    "        best_val_loss = np.inf\n",
    "        embedding_initial=sess.run('embedding:0')\n",
    "        \n",
    "        if  print_test:\n",
    "            # Training cycle\n",
    "            previous_eval_loss = []\n",
    "            best_val_epoch = -1\n",
    "            strikes = 0\n",
    "            print('Start Training cycle...')\n",
    "            for epoch in range(training_epochs):\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(data_size/batch_size)\n",
    "                # Loop over all batches\n",
    "                if epoch %10==0:print('Epoch:',epoch,'total_batch:',total_batch)\n",
    "                    \n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = get_batch(train_set,i)\n",
    "                    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                    _, c, out = sess.run([optimizer, cost, pred], feed_dict={input: batch_x,\n",
    "                                                                 target: batch_y})\n",
    "\n",
    "                    # Compute average loss\n",
    "                    avg_cost += c / total_batch\n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%d' % (epoch+1), \"cost=\", \\\n",
    "                        \"{:.9f}\".format(avg_cost))\n",
    "                c_valid = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "                print(\"Valid error %4f\" % (c_valid))\n",
    "                previous_eval_loss.append(c_valid)\n",
    "                improve_valid = previous_eval_loss[-1] < best_val_loss\n",
    "\n",
    "                if improve_valid:\n",
    "                    best_val_loss = previous_eval_loss[-1]\n",
    "                    best_val_epoch = epoch\n",
    "                    # Save checkpoint.\n",
    "                    saver.save(sess, checkpoint_path,global_step=epoch)\n",
    "                else:\n",
    "                    strikes += 1\n",
    "#                 if strikes > 3:\n",
    "#                     break\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "        input_test, target_test = test_set\n",
    "        c_test = sess.run(cost, feed_dict={input: input_test, target: target_test})\n",
    "\n",
    "\n",
    "        print(\"Test error %.9f\" % (c_test))\n",
    "        print(\"Best validation %.9f\" % (best_val_loss))\n",
    "        \n",
    "        print('訓練完成')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Create model ...\n",
      "WARNING:tensorflow:From <ipython-input-5-524191929ab6>:25: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:189: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-6d44bcd4f217>:39: all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Please use tf.global_variables instead.\n",
      "Start training ...\n",
      "初始化tf變數...\n",
      "Start Training cycle...\n",
      "Epoch: 0 total_batch: 39669\n",
      "Epoch: 1 cost= 6.721846926\n",
      "Valid error 6.044928\n",
      "Epoch: 2 cost= 6.024585307\n",
      "Valid error 6.044780\n",
      "Epoch: 3 cost= 6.024581738\n",
      "Valid error 6.044704\n",
      "Epoch: 4 cost= 6.024581636\n",
      "Valid error 6.044694\n",
      "Epoch: 5 cost= 6.024581536\n",
      "Valid error 6.044688\n",
      "Epoch: 6 cost= 6.024581438\n",
      "Valid error 6.044745\n",
      "Epoch: 7 cost= 6.024581342\n",
      "Valid error 6.044856\n",
      "Epoch: 8 cost= 6.024581267\n",
      "Valid error 6.044856\n",
      "Epoch: 9 cost= 6.024581169\n",
      "Valid error 6.044731\n",
      "Optimization Finished!\n",
      "Test error 6.034627914\n",
      "Best validation 6.044688225\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練完後神經網路隱藏層的權重可以拿來當每個和弦的Embedding\n",
    "embeddings為lookup table,維度12X1024，12是訓練神經網路時先把每個和弦當作一個字並用12-vecotor來表徵，1024是隱藏層節點數 <br>\n",
    "例:C和弦onset的位置為[0, 4, 7] <br>\n",
    "則拿出lookup table位置為[0,4,7]的三個row\n",
    "然後把3個row加總起來變成一個1X1024維度的陣列當做C和弦的Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save_models/linear\\linear_D1024.ckpt-6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.885763</td>\n",
       "      <td>-0.698374</td>\n",
       "      <td>-0.985356</td>\n",
       "      <td>-0.168804</td>\n",
       "      <td>-1.462866</td>\n",
       "      <td>-1.173522</td>\n",
       "      <td>0.771879</td>\n",
       "      <td>0.330421</td>\n",
       "      <td>0.843977</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765034</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>-0.951852</td>\n",
       "      <td>-1.100772</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>1.653568</td>\n",
       "      <td>1.865348</td>\n",
       "      <td>-0.297716</td>\n",
       "      <td>-0.945742</td>\n",
       "      <td>2.476066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.564719</td>\n",
       "      <td>-0.497007</td>\n",
       "      <td>-1.393687</td>\n",
       "      <td>-0.728143</td>\n",
       "      <td>-0.716429</td>\n",
       "      <td>-2.432258</td>\n",
       "      <td>-1.967033</td>\n",
       "      <td>0.184841</td>\n",
       "      <td>1.747492</td>\n",
       "      <td>-0.963003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602678</td>\n",
       "      <td>0.996899</td>\n",
       "      <td>-0.049030</td>\n",
       "      <td>-2.182903</td>\n",
       "      <td>-0.445242</td>\n",
       "      <td>0.466168</td>\n",
       "      <td>1.033728</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>0.534260</td>\n",
       "      <td>1.432744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.147131</td>\n",
       "      <td>0.338825</td>\n",
       "      <td>0.190830</td>\n",
       "      <td>-0.465612</td>\n",
       "      <td>0.293960</td>\n",
       "      <td>0.851809</td>\n",
       "      <td>0.926844</td>\n",
       "      <td>0.542515</td>\n",
       "      <td>-0.390931</td>\n",
       "      <td>1.758892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351451</td>\n",
       "      <td>-0.998305</td>\n",
       "      <td>-0.953686</td>\n",
       "      <td>1.127539</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>-0.498805</td>\n",
       "      <td>-1.194230</td>\n",
       "      <td>-0.379888</td>\n",
       "      <td>-0.332850</td>\n",
       "      <td>-1.293034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.448611</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>-0.106104</td>\n",
       "      <td>-1.350085</td>\n",
       "      <td>-1.208089</td>\n",
       "      <td>-0.686389</td>\n",
       "      <td>0.676287</td>\n",
       "      <td>0.910190</td>\n",
       "      <td>1.533031</td>\n",
       "      <td>-0.017758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125893</td>\n",
       "      <td>1.198886</td>\n",
       "      <td>-0.058276</td>\n",
       "      <td>-2.070835</td>\n",
       "      <td>0.557820</td>\n",
       "      <td>-1.547150</td>\n",
       "      <td>-0.506189</td>\n",
       "      <td>-0.566411</td>\n",
       "      <td>0.090274</td>\n",
       "      <td>-1.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.008666</td>\n",
       "      <td>0.746809</td>\n",
       "      <td>-1.696258</td>\n",
       "      <td>1.211193</td>\n",
       "      <td>-1.171438</td>\n",
       "      <td>0.216586</td>\n",
       "      <td>-0.923916</td>\n",
       "      <td>0.035863</td>\n",
       "      <td>0.850063</td>\n",
       "      <td>-0.356309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.676470</td>\n",
       "      <td>-1.356658</td>\n",
       "      <td>3.318455</td>\n",
       "      <td>-0.204378</td>\n",
       "      <td>2.091613</td>\n",
       "      <td>0.429440</td>\n",
       "      <td>0.789041</td>\n",
       "      <td>-1.254088</td>\n",
       "      <td>-0.519818</td>\n",
       "      <td>1.526186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.885763 -0.698374 -0.985356 -0.168804 -1.462866 -1.173522  0.771879   \n",
       "1 -0.564719 -0.497007 -1.393687 -0.728143 -0.716429 -2.432258 -1.967033   \n",
       "2 -1.147131  0.338825  0.190830 -0.465612  0.293960  0.851809  0.926844   \n",
       "3 -0.448611  0.408163 -0.106104 -1.350085 -1.208089 -0.686389  0.676287   \n",
       "4 -1.008666  0.746809 -1.696258  1.211193 -1.171438  0.216586 -0.923916   \n",
       "\n",
       "       7         8         9       ...         1014      1015      1016  \\\n",
       "0  0.330421  0.843977  0.709352    ...     0.765034  0.081080 -0.951852   \n",
       "1  0.184841  1.747492 -0.963003    ...    -0.602678  0.996899 -0.049030   \n",
       "2  0.542515 -0.390931  1.758892    ...    -0.351451 -0.998305 -0.953686   \n",
       "3  0.910190  1.533031 -0.017758    ...    -0.125893  1.198886 -0.058276   \n",
       "4  0.035863  0.850063 -0.356309    ...    -0.676470 -1.356658  3.318455   \n",
       "\n",
       "       1017      1018      1019      1020      1021      1022      1023  \n",
       "0 -1.100772  0.257062  1.653568  1.865348 -0.297716 -0.945742  2.476066  \n",
       "1 -2.182903 -0.445242  0.466168  1.033728  0.939471  0.534260  1.432744  \n",
       "2  1.127539  0.822034 -0.498805 -1.194230 -0.379888 -0.332850 -1.293034  \n",
       "3 -2.070835  0.557820 -1.547150 -0.506189 -0.566411  0.090274 -1.076528  \n",
       "4 -0.204378  2.091613  0.429440  0.789041 -1.254088 -0.519818  1.526186  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_trained=load_embeddings('save_models/linear')\n",
    "pd.DataFrame(embeddings_trained).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.475685</td>\n",
       "      <td>0.913832</td>\n",
       "      <td>-3.746457</td>\n",
       "      <td>1.352629</td>\n",
       "      <td>-1.555308</td>\n",
       "      <td>-1.950082</td>\n",
       "      <td>-0.153541</td>\n",
       "      <td>0.78741</td>\n",
       "      <td>0.735403</td>\n",
       "      <td>-0.927289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100187</td>\n",
       "      <td>-1.417388</td>\n",
       "      <td>1.308784</td>\n",
       "      <td>-2.470891</td>\n",
       "      <td>1.78009</td>\n",
       "      <td>2.126603</td>\n",
       "      <td>1.601808</td>\n",
       "      <td>-2.80539</td>\n",
       "      <td>-2.189459</td>\n",
       "      <td>3.402207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -2.475685  0.913832 -3.746457  1.352629 -1.555308 -1.950082 -0.153541   \n",
       "\n",
       "      7         8         9       ...         1014      1015      1016  \\\n",
       "0  0.78741  0.735403 -0.927289    ...    -0.100187 -1.417388  1.308784   \n",
       "\n",
       "       1017     1018      1019      1020     1021      1022      1023  \n",
       "0 -2.470891  1.78009  2.126603  1.601808 -2.80539 -2.189459  3.402207  \n",
       "\n",
       "[1 rows x 1024 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=chord_vector.get('C:maj')\n",
    "Cmaj_Embedding=embeddings_trained[index].sum(axis=0).reshape(1, 1024)\n",
    "pd.DataFrame(Cmaj_Embedding)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 208.666666,
   "position": {
    "height": "230px",
    "left": "743px",
    "right": "20px",
    "top": "-6px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
