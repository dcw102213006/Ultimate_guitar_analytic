{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "import sys\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "Linear model implementation in tensorflow\n",
    "'''\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from chord2vec.linear_models import data_processing as dp\n",
    "import numpy as np\n",
    "import random\n",
    "import importlib\n",
    "importlib.reload(dp)\n",
    "import time\n",
    "from ast import literal_eval\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "會把資料整理成train_chords、test_chords、valid_chords三個lists <br>\n",
    "整理過的話直接跳到 \n",
    "# 儲存train_chords、test_chords、valid_chords\n",
    "此chunk，以製作train_set來練chord_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "song_train_merged=pd.read_csv('../../data/song_train_merged_transferkey0425.csv',encoding=\"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0.1.1</th>\n",
       "      <th>_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>chord</th>\n",
       "      <th>error</th>\n",
       "      <th>rating</th>\n",
       "      <th>tab_href</th>\n",
       "      <th>tab_title</th>\n",
       "      <th>version</th>\n",
       "      <th>song_name</th>\n",
       "      <th>song_detector_chord</th>\n",
       "      <th>song_chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>5cada0049fc5af34a460ae05</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/art_...</td>\n",
       "      <td>Art For Arts Sake</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Art For Arts Sake 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...</td>\n",
       "      <td>[N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5cada0049fc5af34a460ae07</td>\n",
       "      <td>10cc</td>\n",
       "      <td>[G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>https://tabs.ultimate-guitar.com/tab/10cc/baro...</td>\n",
       "      <td>Baron Samedi</td>\n",
       "      <td>Ver 1</td>\n",
       "      <td>Baron Samedi 10cc</td>\n",
       "      <td>[{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...</td>\n",
       "      <td>[A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1  Unnamed: 0.1.1                       _id artist  \\\n",
       "0           0             0              28  5cada0049fc5af34a460ae05   10cc   \n",
       "1           1             1              29  5cada0049fc5af34a460ae07   10cc   \n",
       "\n",
       "                                               chord  error rating  \\\n",
       "0  [G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...      0      9   \n",
       "1  [G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...      0      3   \n",
       "\n",
       "                                            tab_href          tab_title  \\\n",
       "0  https://tabs.ultimate-guitar.com/tab/10cc/art_...  Art For Arts Sake   \n",
       "1  https://tabs.ultimate-guitar.com/tab/10cc/baro...       Baron Samedi   \n",
       "\n",
       "  version               song_name  \\\n",
       "0   Ver 1  Art For Arts Sake 10cc   \n",
       "1   Ver 1       Baron Samedi 10cc   \n",
       "\n",
       "                                 song_detector_chord  \\\n",
       "0  [{'st': 0, 'et': 0.511, 'ochord': 'N'}, {'st':...   \n",
       "1  [{'st': 0, 'et': 3.413, 'ochord': 'A:min'}, {'...   \n",
       "\n",
       "                                          song_chord  \n",
       "0  [N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...  \n",
       "1  [A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=song_train_merged.copy()\n",
    "df['song_chord']=df['song_chord'].apply(literal_eval)\n",
    "df['chord']=df['chord'].apply(literal_eval)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A:maj',\n",
       " 'A:min',\n",
       " 'Ab:maj',\n",
       " 'Ab:min',\n",
       " 'B:maj',\n",
       " 'Bb:maj',\n",
       " 'Bb:min',\n",
       " 'C:maj',\n",
       " 'D:maj',\n",
       " 'Db:maj',\n",
       " 'Db:min',\n",
       " 'E:maj',\n",
       " 'E:min',\n",
       " 'Eb:maj',\n",
       " 'Eb:min',\n",
       " 'F:maj',\n",
       " 'F:min',\n",
       " 'G:maj',\n",
       " 'Gb:maj',\n",
       " 'Gb:min',\n",
       " 'N'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#資料集中的所有和絃類別\n",
    "chord_list=[]\n",
    "for row in df.chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "for row in df.song_chord:\n",
    "    for chord in row:\n",
    "        chord_list.append(chord)\n",
    "chord_list=set(chord_list)\n",
    "chord_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "401"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del chord_list\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord2Vec:\n",
    "1.準備好train_data，每一個元素是一個和弦，記錄其onset的index <br>\n",
    "例:以12-vector 做many-hot-encoding，C和弦onset的位置為1,5,8 <br>\n",
    "2.把df的chord(row是每篇吉他譜和弦)欄位與song_chord(吉他譜對應的歌曲做完和弦辨識的欄位)合併成一個欄位<br>\n",
    "以便切train、test、valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chord_vector = {\n",
    "               \n",
    "        'C:maj':  [0,4,7],\n",
    "        'Db:maj': [1,5,8],\n",
    "        'Db:min': [1,4,8],\n",
    "        'D:maj':  [2,7,9],\n",
    "        'Eb:maj': [3,7,10],\n",
    "        'Eb:min': [3,6,10],\n",
    "        'E:maj':  [4,8,11],\n",
    "        'E:min':  [4,7,11],\n",
    "        'F:maj':  [0,5,9],\n",
    "        'F:min':  [0,4,9],\n",
    "        'Gb:maj': [1,6,10],\n",
    "        'Gb:min': [1,6,9],\n",
    "        'G:maj':  [2,7,11],\n",
    "        'G:min':  [2,7,10],\n",
    "        'Ab:maj': [0,3,8],\n",
    "        'Ab:min': [3,8,11],\n",
    "        'A:maj':  [1,4,9],\n",
    "        'A:min':  [0,4,9],\n",
    "        'Bb:maj': [2,5,10],\n",
    "        'Bb:min': [1,5,10],\n",
    "        'B:maj':  [2,6,11],\n",
    "        'B:min':  [1,6,11]    \n",
    "   \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "用chord2vec_df這張大df切train、test、valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chord</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Bb:maj, Bb:maj, C:maj, C:maj, Bb:maj, Bb:maj,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               chord\n",
       "0  [G:maj, C:maj, G:maj, Eb:maj, G:maj, G:maj, N,...\n",
       "1  [N, D:maj, F:maj, D:maj, G:maj, G:maj, Db:maj,...\n",
       "2  [G:maj, N, C:maj, Bb:maj, N, G:maj, C:maj, A:m...\n",
       "3  [A:min, G:maj, F:maj, C:maj, D:maj, C:maj, Bb:...\n",
       "4  [Bb:maj, Bb:maj, C:maj, C:maj, Bb:maj, Bb:maj,..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chord2vec_df=df[['chord','song_chord']].stack().reset_index()\n",
    "chord2vec_df[0]\n",
    "chord2vec_df=pd.DataFrame({'chord':chord2vec_df[0]})\n",
    "chord2vec_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: 28142\n",
      "test: 6031\n",
      "valid: 6031\n"
     ]
    }
   ],
   "source": [
    "chord2vec_df_train, chord2vec_df_test = train_test_split(chord2vec_df, test_size=0.3, random_state=2019)\n",
    "chord2vec_df_test,chord2vec_df_valid=train_test_split(chord2vec_df_test, test_size=0.5, random_state=2019)\n",
    "\n",
    "print('train:',len(chord2vec_df_train))\n",
    "print('test:',len(chord2vec_df_test))\n",
    "print('valid:',len(chord2vec_df_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#chord_word_data:list,存吉他譜與歌曲的和弦進行，一個和弦是一個字，一首歌曲譜是一篇文章\n",
    "train_data=[]\n",
    "test_data=[]\n",
    "valid_data=[]\n",
    "for row in chord2vec_df_train.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    train_data.append(row_list)\n",
    "for row in chord2vec_df_test.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    test_data.append(row_list)\n",
    "for row in chord2vec_df_valid.chord:\n",
    "    row_list=[]\n",
    "    for chord in row:\n",
    "        if chord in chord_vector:\n",
    "            row_list.append(chord_vector.get(chord))\n",
    "    valid_data.append(row_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chord2Vec需要每個字(和弦)的上下文序列作為訓練資料 \n",
    "使用dp.make_chord_context(train_data,test_data,valid_data,1)幫和弦配對上下文 <br>\n",
    "使用prepare_training_data(train_chords,test_chords,valid_chords)把train_set，test_set,valid_set做好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38.38114953041077"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#需要1~2分鐘\n",
    "start = time.time()\n",
    "train_chords, test_chords , valid_chords = dp.make_chord_context(train_data,test_data,valid_data,1)\n",
    "time.time()-start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#沒用到的變數先刪掉  節省記憶體\n",
    "del chord2vec_df_train,chord2vec_df_test,chord2vec_df_valid\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "685"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del chord2vec_df,df,row,row_list,song_train_merged\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del   train_data,test_data,valid_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 儲存train_chords、test_chords、valid_chords\n",
    "train_chords已經做完context配對  <br>\n",
    "接下來要製作train_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "# out = open(\"LinearModel_data/0513/train_chords.pkl\",\"wb\")\n",
    "# pickle.dump(train_chords, out)\n",
    "# out = open(\"LinearModel_data/0513/test_chords.pkl\",\"wb\")\n",
    "# pickle.dump(test_chords, out)\n",
    "# out = open(\"LinearModel_data/0513/valid_chords.pkl\",\"wb\")\n",
    "# pickle.dump(valid_chords, out)\n",
    "# print('ok')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('LinearModel_data/train_chords.pkl', 'rb') as pickle_load:\n",
    "    train_chords = pickle.load(pickle_load)\n",
    "with open('LinearModel_data/test_chords.pkl', 'rb') as pickle_load:\n",
    "    test_chords = pickle.load(pickle_load)\n",
    "with open('LinearModel_data/valid_chords.pkl', 'rb') as pickle_load:\n",
    "    valid_chords = pickle.load(pickle_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_training_data(train_chords,test_chords,valid_chords):\n",
    "    print('Loading data ...')\n",
    " \n",
    "    train_set = dp.generate_binary_vectors(train_chords)\n",
    "    # input_train, target_train = train_set\n",
    "    del  train_chords\n",
    "    gc.collect()\n",
    "    test_set = dp.generate_binary_vectors(test_chords)\n",
    "    del  test_chords\n",
    "    gc.collect()\n",
    "    valid_set = dp.generate_binary_vectors(valid_chords)\n",
    "    del  valid_chords\n",
    "    gc.collect()\n",
    "    # input_valid, target_valid = valid_set\n",
    "    \n",
    "    data_size = len(train_set[0])\n",
    "    data_size_valid = len(valid_set[0])\n",
    "    data_size_te = len(test_set[0])\n",
    "\n",
    "    total_batch = int(data_size / batch_size)\n",
    "    total_batch_valid = int(data_size_valid / batch_size)\n",
    "    total_batch_test = int(data_size_te / batch_size)\n",
    "\n",
    "    return train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 200\n",
    "batch_size = 128\n",
    "display_step = 1\n",
    "\n",
    "# Network Parameters\n",
    "D = 500 # 1st layer number of features\n",
    "NUM_NOTES = 12 #nums of Vocab\n",
    "\n",
    "# tf Graph input\n",
    "input = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "target = tf.placeholder(\"float\", [None, NUM_NOTES])\n",
    "\n",
    "# Create model\n",
    "def linear(input, weights):\n",
    "    hidden = tf.matmul( \n",
    "        tf.truediv(\n",
    "            input, \n",
    "            tf.maximum(\n",
    "                1.0,\n",
    "                tf.reduce_sum(\n",
    "                    input, \n",
    "                    1, \n",
    "                    keep_dims=True\n",
    "                )\n",
    "            ) \n",
    "        ) ,\n",
    "        weights['hidden']\n",
    "    ) #+ bias['hidden1']\n",
    "    out_layer = tf.matmul(\n",
    "        hidden,\n",
    "        weights['out'])# + bias['out']\n",
    "    return out_layer\n",
    "\n",
    "# Store layers weight & bias\n",
    "weights = {\n",
    "    'hidden': tf.Variable(tf.random_normal([NUM_NOTES, D]),name='embedding'),\n",
    "    'out': tf.Variable(tf.random_normal([D, NUM_NOTES]))\n",
    "}\n",
    "\n",
    "bias = {\n",
    "    'hidden': tf.Variable(tf.random_normal([D])),\n",
    "    'out': tf.Variable(tf.random_normal([NUM_NOTES]))\n",
    "}\n",
    "embedding_initial=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# loads the embeddings variable from the tensorflow checkpoint\n",
    "def load_embeddings(checkpoint_path):\n",
    "    with tf.Session() as session:\n",
    "        if checkpoint_path:\n",
    "            saver = tf.train.import_meta_graph(checkpoint_path+'/linear_D1024.ckpt-6.meta')\n",
    "            saver.restore(session, tf.train.latest_checkpoint(checkpoint_path))\n",
    "          \n",
    "            return session.run('embedding:0')\n",
    "def get_batch(data_set,id, stoch=False):\n",
    "    if stoch:\n",
    "        transpose_data_set = list(map(list, zip(*data_set)))\n",
    "        batch = random.sample(transpose_data_set, batch_size)\n",
    "        batch_input,batch_target = list(map(list, zip(*batch)))\n",
    "        return batch_input,batch_target\n",
    "    batch_id = id + 1\n",
    "    input, target = data_set\n",
    "    return input[(batch_id * batch_size - batch_size):(batch_id * batch_size)], target[(batch_id * batch_size - batch_size):(batch_id * batch_size)]\n",
    "\n",
    "\n",
    "def train(checkpoint_path='save_models/linear/0507/linear_D1024.ckpt',load_model=None,print_train=True, print_test=True):\n",
    "    train_set, test_set, valid_set, total_batch, total_batch_test, total_batch_valid = prepare_training_data(train_chords,test_chords,valid_chords)\n",
    "    data_size = len(train_set[0])\n",
    "\n",
    "    # Construct model\n",
    "    print('Create model ...')\n",
    "    \n",
    "    pred = linear(input, weights)\n",
    "\n",
    "    # Define loss and optimizer\n",
    "    cost = tf.reduce_mean(tf.reduce_sum(tf.nn.sigmoid_cross_entropy_with_logits(logits=pred, labels=target),1))\n",
    "\n",
    "\n",
    "    #optimizer = tf.train.AdamOptimizer(epsilon=1e-01,learning_rate=learning_rate).minimize(cost)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "\n",
    "    # Initializing the variables\n",
    "    init = tf.initialize_all_variables()\n",
    "    saver = tf.train.Saver(tf.all_variables(),max_to_keep=1)\n",
    "    \n",
    "    input_valid, target_valid = valid_set\n",
    "\n",
    "    # Launch the graph\n",
    "    print('Start training ...')\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # checkpoint = False #tf.train.get_checkpoint_state('save_models/linear')\n",
    "        # if checkpoint and tf.gfile.Exists(checkpoint.model_checkpoint_path):\n",
    "        #     print(\"Reading model parameters from %s\" % checkpoint.model_checkpoint_path)\n",
    "        #     saver.restore(sess, checkpoint.model_checkpoint_path)\n",
    "        #     best_val_loss = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "        \n",
    "        print('初始化tf變數...')\n",
    "        sess.run(init)\n",
    "        best_val_loss = np.inf\n",
    "        embedding_initial=sess.run('embedding:0')\n",
    "        \n",
    "        if  print_test:\n",
    "            # Training cycle\n",
    "            previous_eval_loss = []\n",
    "            best_val_epoch = -1\n",
    "            strikes = 0\n",
    "            print('Start Training cycle...')\n",
    "            for epoch in range(training_epochs):\n",
    "                avg_cost = 0.\n",
    "                total_batch = int(data_size/batch_size)\n",
    "                # Loop over all batches\n",
    "                if epoch %10==0:print('Epoch:',epoch,'total_batch:',total_batch)\n",
    "                    \n",
    "                for i in range(total_batch):\n",
    "                    batch_x, batch_y = get_batch(train_set,i)\n",
    "                    # Run optimization op (backprop) and cost op (to get loss value)\n",
    "                    _, c, out = sess.run([optimizer, cost, pred], feed_dict={input: batch_x,\n",
    "                                                                 target: batch_y})\n",
    "\n",
    "                    # Compute average loss\n",
    "                    avg_cost += c / total_batch\n",
    "                # Display logs per epoch step\n",
    "                if epoch % display_step == 0:\n",
    "                    print(\"Epoch:\", '%d' % (epoch+1), \"cost=\", \\\n",
    "                        \"{:.9f}\".format(avg_cost))\n",
    "                c_valid = sess.run(cost, feed_dict={input: input_valid, target: target_valid})\n",
    "                print(\"Valid error %4f\" % (c_valid))\n",
    "                previous_eval_loss.append(c_valid)\n",
    "                improve_valid = previous_eval_loss[-1] < best_val_loss\n",
    "\n",
    "                if improve_valid:\n",
    "                    best_val_loss = previous_eval_loss[-1]\n",
    "                    best_val_epoch = epoch\n",
    "                    # Save checkpoint.\n",
    "                    saver.save(sess, checkpoint_path,global_step=epoch)\n",
    "                else:\n",
    "                    strikes += 1\n",
    "#                 if strikes > 3:\n",
    "#                     break\n",
    "            print(\"Optimization Finished!\")\n",
    "\n",
    "        input_test, target_test = test_set\n",
    "        c_test = sess.run(cost, feed_dict={input: input_test, target: target_test})\n",
    "\n",
    "\n",
    "        print(\"Test error %.9f\" % (c_test))\n",
    "        print(\"Best validation %.9f\" % (best_val_loss))\n",
    "        \n",
    "        print('訓練完成')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data ...\n",
      "Create model ...\n",
      "Start training ...\n",
      "初始化tf變數...\n",
      "Start Training cycle...\n",
      "Epoch: 0 total_batch: 39669\n",
      "Epoch: 1 cost= 6.666183077\n",
      "Valid error 6.045089\n",
      "Epoch: 2 cost= 6.024536747\n",
      "Valid error 6.045136\n",
      "Epoch: 3 cost= 6.024531387\n",
      "Valid error 6.045253\n",
      "Epoch: 4 cost= 6.024531363\n",
      "Valid error 6.045240\n",
      "Epoch: 5 cost= 6.024531283\n",
      "Valid error 6.045240\n",
      "Epoch: 6 cost= 6.024531191\n",
      "Valid error 6.045244\n",
      "Epoch: 7 cost= 6.024531089\n",
      "Valid error 6.045189\n",
      "Epoch: 8 cost= 6.024531005\n",
      "Valid error 6.045182\n",
      "Epoch: 9 cost= 6.024530902\n",
      "Valid error 6.045063\n",
      "Epoch: 10 cost= 6.024530801\n",
      "Valid error 6.045058\n",
      "Epoch: 10 total_batch: 39669\n",
      "Epoch: 11 cost= 6.024530709\n",
      "Valid error 6.045064\n",
      "Epoch: 12 cost= 6.024530613\n",
      "Valid error 6.045083\n",
      "Epoch: 13 cost= 6.024530524\n",
      "Valid error 6.045098\n",
      "Epoch: 14 cost= 6.024530441\n",
      "Valid error 6.045105\n",
      "Epoch: 15 cost= 6.024530351\n",
      "Valid error 6.045105\n",
      "Epoch: 16 cost= 6.024530233\n",
      "Valid error 6.045098\n",
      "Epoch: 17 cost= 6.024530146\n",
      "Valid error 6.045101\n",
      "Epoch: 18 cost= 6.024530066\n",
      "Valid error 6.045067\n",
      "Epoch: 19 cost= 6.024529956\n",
      "Valid error 6.045046\n",
      "Epoch: 20 cost= 6.024529860\n",
      "Valid error 6.045062\n",
      "Epoch: 20 total_batch: 39669\n",
      "Epoch: 21 cost= 6.024529770\n",
      "Valid error 6.045088\n",
      "Epoch: 22 cost= 6.024529671\n",
      "Valid error 6.045075\n",
      "Epoch: 23 cost= 6.024529590\n",
      "Valid error 6.045079\n",
      "Epoch: 24 cost= 6.024529484\n",
      "Valid error 6.045077\n",
      "Epoch: 25 cost= 6.024529388\n",
      "Valid error 6.045097\n",
      "Epoch: 26 cost= 6.024529296\n",
      "Valid error 6.045090\n",
      "Epoch: 27 cost= 6.024529204\n",
      "Valid error 6.045070\n",
      "Epoch: 28 cost= 6.024529109\n",
      "Valid error 6.045073\n",
      "Epoch: 29 cost= 6.024529010\n",
      "Valid error 6.045071\n",
      "Epoch: 30 cost= 6.024528930\n",
      "Valid error 6.045069\n",
      "Epoch: 30 total_batch: 39669\n",
      "Epoch: 31 cost= 6.024528842\n",
      "Valid error 6.045044\n",
      "Epoch: 32 cost= 6.024528733\n",
      "Valid error 6.045053\n",
      "Epoch: 33 cost= 6.024528648\n",
      "Valid error 6.045206\n",
      "Epoch: 34 cost= 6.024528552\n",
      "Valid error 6.045222\n",
      "Epoch: 35 cost= 6.024528454\n",
      "Valid error 6.045332\n",
      "Epoch: 36 cost= 6.024528356\n",
      "Valid error 6.045288\n",
      "Epoch: 37 cost= 6.024528279\n",
      "Valid error 6.045287\n",
      "Epoch: 38 cost= 6.024528169\n",
      "Valid error 6.045304\n",
      "Epoch: 39 cost= 6.024528073\n",
      "Valid error 6.045311\n",
      "Epoch: 40 cost= 6.024527981\n",
      "Valid error 6.045038\n",
      "Epoch: 40 total_batch: 39669\n",
      "Epoch: 41 cost= 6.024527890\n",
      "Valid error 6.045023\n",
      "Epoch: 42 cost= 6.024527787\n",
      "Valid error 6.045030\n",
      "Epoch: 43 cost= 6.024527714\n",
      "Valid error 6.045059\n",
      "Epoch: 44 cost= 6.024527614\n",
      "Valid error 6.045008\n",
      "Epoch: 45 cost= 6.024527521\n",
      "Valid error 6.044908\n",
      "Epoch: 46 cost= 6.024527432\n",
      "Valid error 6.044863\n",
      "Epoch: 47 cost= 6.024527345\n",
      "Valid error 6.044662\n",
      "Epoch: 48 cost= 6.024527233\n",
      "Valid error 6.044660\n",
      "Epoch: 49 cost= 6.024527142\n",
      "Valid error 6.044662\n",
      "Epoch: 50 cost= 6.024527053\n",
      "Valid error 6.044629\n",
      "Epoch: 50 total_batch: 39669\n",
      "Epoch: 51 cost= 6.024526950\n",
      "Valid error 6.044646\n",
      "Epoch: 52 cost= 6.024526853\n",
      "Valid error 6.044651\n",
      "Epoch: 53 cost= 6.024526763\n",
      "Valid error 6.044647\n",
      "Epoch: 54 cost= 6.024526660\n",
      "Valid error 6.044651\n",
      "Epoch: 55 cost= 6.024526579\n",
      "Valid error 6.044666\n",
      "Epoch: 56 cost= 6.024526489\n",
      "Valid error 6.044664\n",
      "Epoch: 57 cost= 6.024526415\n",
      "Valid error 6.044674\n",
      "Epoch: 58 cost= 6.024526301\n",
      "Valid error 6.044675\n",
      "Epoch: 59 cost= 6.024526226\n",
      "Valid error 6.044658\n",
      "Epoch: 60 cost= 6.024526126\n",
      "Valid error 6.044643\n",
      "Epoch: 60 total_batch: 39669\n",
      "Epoch: 61 cost= 6.024526017\n",
      "Valid error 6.044651\n",
      "Epoch: 62 cost= 6.024525912\n",
      "Valid error 6.044633\n",
      "Epoch: 63 cost= 6.024525820\n",
      "Valid error 6.044640\n",
      "Epoch: 64 cost= 6.024525736\n",
      "Valid error 6.044541\n",
      "Epoch: 65 cost= 6.024525647\n",
      "Valid error 6.044514\n",
      "Epoch: 66 cost= 6.024525568\n",
      "Valid error 6.044518\n",
      "Epoch: 67 cost= 6.024525460\n",
      "Valid error 6.044521\n",
      "Epoch: 68 cost= 6.024525358\n",
      "Valid error 6.044412\n",
      "Epoch: 69 cost= 6.024525264\n",
      "Valid error 6.044419\n",
      "Epoch: 70 cost= 6.024525175\n",
      "Valid error 6.044418\n",
      "Epoch: 70 total_batch: 39669\n",
      "Epoch: 71 cost= 6.024525095\n",
      "Valid error 6.044418\n",
      "Epoch: 72 cost= 6.024524990\n",
      "Valid error 6.044432\n",
      "Epoch: 73 cost= 6.024524900\n",
      "Valid error 6.044448\n",
      "Epoch: 74 cost= 6.024524827\n",
      "Valid error 6.044189\n",
      "Epoch: 75 cost= 6.024524711\n",
      "Valid error 6.044195\n",
      "Epoch: 76 cost= 6.024524626\n",
      "Valid error 6.044193\n",
      "Epoch: 77 cost= 6.024524530\n",
      "Valid error 6.044149\n",
      "Epoch: 78 cost= 6.024524431\n",
      "Valid error 6.044191\n",
      "Epoch: 79 cost= 6.024524337\n",
      "Valid error 6.044193\n",
      "Epoch: 80 cost= 6.024524243\n",
      "Valid error 6.044127\n",
      "Epoch: 80 total_batch: 39669\n",
      "Epoch: 81 cost= 6.024524152\n",
      "Valid error 6.044179\n",
      "Epoch: 82 cost= 6.024524040\n",
      "Valid error 6.044197\n",
      "Epoch: 83 cost= 6.024523959\n",
      "Valid error 6.044196\n",
      "Epoch: 84 cost= 6.024523843\n",
      "Valid error 6.044177\n",
      "Epoch: 85 cost= 6.024523763\n",
      "Valid error 6.044177\n",
      "Epoch: 86 cost= 6.024523682\n",
      "Valid error 6.044166\n",
      "Epoch: 87 cost= 6.024523584\n",
      "Valid error 6.044107\n",
      "Epoch: 88 cost= 6.024523483\n",
      "Valid error 6.044111\n",
      "Epoch: 89 cost= 6.024523394\n",
      "Valid error 6.044129\n",
      "Epoch: 90 cost= 6.024523285\n",
      "Valid error 6.044123\n",
      "Epoch: 90 total_batch: 39669\n",
      "Epoch: 91 cost= 6.024523214\n",
      "Valid error 6.044122\n",
      "Epoch: 92 cost= 6.024523120\n",
      "Valid error 6.044121\n",
      "Epoch: 93 cost= 6.024523013\n",
      "Valid error 6.044073\n",
      "Epoch: 94 cost= 6.024522923\n",
      "Valid error 6.044068\n",
      "Epoch: 95 cost= 6.024522816\n",
      "Valid error 6.044065\n",
      "Epoch: 96 cost= 6.024522722\n",
      "Valid error 6.044174\n",
      "Epoch: 97 cost= 6.024522631\n",
      "Valid error 6.043673\n",
      "Epoch: 98 cost= 6.024522553\n",
      "Valid error 6.043683\n",
      "Epoch: 99 cost= 6.024522470\n",
      "Valid error 6.043697\n",
      "Epoch: 100 cost= 6.024522369\n",
      "Valid error 6.043707\n",
      "Epoch: 100 total_batch: 39669\n",
      "Epoch: 101 cost= 6.024522281\n",
      "Valid error 6.043969\n",
      "Epoch: 102 cost= 6.024522172\n",
      "Valid error 6.043968\n",
      "Epoch: 103 cost= 6.024522084\n",
      "Valid error 6.043985\n",
      "Epoch: 104 cost= 6.024522000\n",
      "Valid error 6.043988\n",
      "Epoch: 105 cost= 6.024521900\n",
      "Valid error 6.043996\n",
      "Epoch: 106 cost= 6.024521806\n",
      "Valid error 6.043775\n",
      "Epoch: 107 cost= 6.024521713\n",
      "Valid error 6.043821\n",
      "Epoch: 108 cost= 6.024521637\n",
      "Valid error 6.043851\n",
      "Epoch: 109 cost= 6.024521542\n",
      "Valid error 6.043874\n",
      "Epoch: 110 cost= 6.024521436\n",
      "Valid error 6.043791\n",
      "Epoch: 110 total_batch: 39669\n",
      "Epoch: 111 cost= 6.024521365\n",
      "Valid error 6.043704\n",
      "Epoch: 112 cost= 6.024521257\n",
      "Valid error 6.043724\n",
      "Epoch: 113 cost= 6.024521160\n",
      "Valid error 6.043765\n",
      "Epoch: 114 cost= 6.024521068\n",
      "Valid error 6.043761\n",
      "Epoch: 115 cost= 6.024520972\n",
      "Valid error 6.043760\n",
      "Epoch: 116 cost= 6.024520882\n",
      "Valid error 6.043764\n",
      "Epoch: 117 cost= 6.024520781\n",
      "Valid error 6.043828\n",
      "Epoch: 118 cost= 6.024520706\n",
      "Valid error 6.043828\n",
      "Epoch: 119 cost= 6.024520615\n",
      "Valid error 6.043853\n",
      "Epoch: 120 cost= 6.024520516\n",
      "Valid error 6.043869\n",
      "Epoch: 120 total_batch: 39669\n",
      "Epoch: 121 cost= 6.024520414\n",
      "Valid error 6.044068\n",
      "Epoch: 122 cost= 6.024520303\n",
      "Valid error 6.044037\n",
      "Epoch: 123 cost= 6.024520227\n",
      "Valid error 6.044075\n",
      "Epoch: 124 cost= 6.024520152\n",
      "Valid error 6.044027\n",
      "Epoch: 125 cost= 6.024520046\n",
      "Valid error 6.044028\n",
      "Epoch: 126 cost= 6.024519943\n",
      "Valid error 6.044052\n",
      "Epoch: 127 cost= 6.024519855\n",
      "Valid error 6.044057\n",
      "Epoch: 128 cost= 6.024519755\n",
      "Valid error 6.044052\n",
      "Epoch: 129 cost= 6.024519680\n",
      "Valid error 6.044048\n",
      "Epoch: 130 cost= 6.024519589\n",
      "Valid error 6.044040\n",
      "Epoch: 130 total_batch: 39669\n",
      "Epoch: 131 cost= 6.024519504\n",
      "Valid error 6.044024\n",
      "Epoch: 132 cost= 6.024519393\n",
      "Valid error 6.044024\n",
      "Epoch: 133 cost= 6.024519301\n",
      "Valid error 6.043761\n",
      "Epoch: 134 cost= 6.024519224\n",
      "Valid error 6.043770\n",
      "Epoch: 135 cost= 6.024519132\n",
      "Valid error 6.043381\n",
      "Epoch: 136 cost= 6.024519030\n",
      "Valid error 6.043421\n",
      "Epoch: 137 cost= 6.024518953\n",
      "Valid error 6.043411\n",
      "Epoch: 138 cost= 6.024518835\n",
      "Valid error 6.043394\n",
      "Epoch: 139 cost= 6.024518736\n",
      "Valid error 6.043399\n",
      "Epoch: 140 cost= 6.024518669\n",
      "Valid error 6.043413\n",
      "Epoch: 140 total_batch: 39669\n",
      "Epoch: 141 cost= 6.024518569\n",
      "Valid error 6.043403\n",
      "Epoch: 142 cost= 6.024518484\n",
      "Valid error 6.043398\n",
      "Epoch: 143 cost= 6.024518387\n",
      "Valid error 6.043393\n",
      "Epoch: 144 cost= 6.024518286\n",
      "Valid error 6.043407\n",
      "Epoch: 145 cost= 6.024518212\n",
      "Valid error 6.043409\n",
      "Epoch: 146 cost= 6.024518107\n",
      "Valid error 6.043401\n",
      "Epoch: 147 cost= 6.024518018\n",
      "Valid error 6.043400\n",
      "Epoch: 148 cost= 6.024517931\n",
      "Valid error 6.043403\n",
      "Epoch: 149 cost= 6.024517829\n",
      "Valid error 6.043400\n",
      "Epoch: 150 cost= 6.024517744\n",
      "Valid error 6.043400\n",
      "Epoch: 150 total_batch: 39669\n",
      "Epoch: 151 cost= 6.024517645\n",
      "Valid error 6.043383\n",
      "Epoch: 152 cost= 6.024517540\n",
      "Valid error 6.043373\n",
      "Epoch: 153 cost= 6.024517459\n",
      "Valid error 6.043397\n",
      "Epoch: 154 cost= 6.024517378\n",
      "Valid error 6.043425\n",
      "Epoch: 155 cost= 6.024517284\n",
      "Valid error 6.043427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156 cost= 6.024517188\n",
      "Valid error 6.043430\n",
      "Epoch: 157 cost= 6.024517088\n",
      "Valid error 6.043426\n",
      "Epoch: 158 cost= 6.024517003\n",
      "Valid error 6.043289\n",
      "Epoch: 159 cost= 6.024516896\n",
      "Valid error 6.043286\n",
      "Epoch: 160 cost= 6.024516808\n",
      "Valid error 6.043326\n",
      "Epoch: 160 total_batch: 39669\n",
      "Epoch: 161 cost= 6.024516715\n",
      "Valid error 6.043332\n",
      "Epoch: 162 cost= 6.024516622\n",
      "Valid error 6.043296\n",
      "Epoch: 163 cost= 6.024516536\n",
      "Valid error 6.043258\n",
      "Epoch: 164 cost= 6.024516452\n",
      "Valid error 6.043282\n",
      "Epoch: 165 cost= 6.024516354\n",
      "Valid error 6.043258\n",
      "Epoch: 166 cost= 6.024516242\n",
      "Valid error 6.043640\n",
      "Epoch: 167 cost= 6.024516160\n",
      "Valid error 6.043642\n",
      "Epoch: 168 cost= 6.024516076\n",
      "Valid error 6.043605\n",
      "Epoch: 169 cost= 6.024515997\n",
      "Valid error 6.043612\n",
      "Epoch: 170 cost= 6.024515889\n",
      "Valid error 6.043629\n",
      "Epoch: 170 total_batch: 39669\n",
      "Epoch: 171 cost= 6.024515780\n",
      "Valid error 6.043631\n",
      "Epoch: 172 cost= 6.024515687\n",
      "Valid error 6.043632\n",
      "Epoch: 173 cost= 6.024515604\n",
      "Valid error 6.043543\n",
      "Epoch: 174 cost= 6.024515521\n",
      "Valid error 6.043521\n",
      "Epoch: 175 cost= 6.024515426\n",
      "Valid error 6.043530\n",
      "Epoch: 176 cost= 6.024515335\n",
      "Valid error 6.043524\n",
      "Epoch: 177 cost= 6.024515249\n",
      "Valid error 6.043525\n",
      "Epoch: 178 cost= 6.024515149\n",
      "Valid error 6.043539\n",
      "Epoch: 179 cost= 6.024515053\n",
      "Valid error 6.043855\n",
      "Epoch: 180 cost= 6.024514983\n",
      "Valid error 6.043967\n",
      "Epoch: 180 total_batch: 39669\n",
      "Epoch: 181 cost= 6.024514880\n",
      "Valid error 6.043981\n",
      "Epoch: 182 cost= 6.024514776\n",
      "Valid error 6.043802\n",
      "Epoch: 183 cost= 6.024514687\n",
      "Valid error 6.043796\n",
      "Epoch: 184 cost= 6.024514607\n",
      "Valid error 6.043795\n",
      "Epoch: 185 cost= 6.024514515\n",
      "Valid error 6.043726\n",
      "Epoch: 186 cost= 6.024514412\n",
      "Valid error 6.043717\n",
      "Epoch: 187 cost= 6.024514331\n",
      "Valid error 6.043714\n",
      "Epoch: 188 cost= 6.024514236\n",
      "Valid error 6.043722\n",
      "Epoch: 189 cost= 6.024514142\n",
      "Valid error 6.043710\n",
      "Epoch: 190 cost= 6.024514064\n",
      "Valid error 6.043641\n",
      "Epoch: 190 total_batch: 39669\n",
      "Epoch: 191 cost= 6.024513972\n",
      "Valid error 6.043592\n",
      "Epoch: 192 cost= 6.024513882\n",
      "Valid error 6.043547\n",
      "Epoch: 193 cost= 6.024513783\n",
      "Valid error 6.043550\n",
      "Epoch: 194 cost= 6.024513694\n",
      "Valid error 6.043566\n",
      "Epoch: 195 cost= 6.024513603\n",
      "Valid error 6.043569\n",
      "Epoch: 196 cost= 6.024513514\n",
      "Valid error 6.043729\n",
      "Epoch: 197 cost= 6.024513413\n",
      "Valid error 6.043727\n",
      "Epoch: 198 cost= 6.024513331\n",
      "Valid error 6.043739\n",
      "Epoch: 199 cost= 6.024513236\n",
      "Valid error 6.043738\n",
      "Epoch: 200 cost= 6.024513149\n",
      "Valid error 6.043832\n",
      "Optimization Finished!\n",
      "Test error 6.033592224\n",
      "Best validation 6.043257713\n",
      "訓練完成\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練完後神經網路隱藏層的權重可以拿來當每個和弦的Embedding\n",
    "embeddings為lookup table,維度12X1024，12是訓練神經網路時先把每個和弦當作一個字並用12-vecotor來表徵，1024是隱藏層節點數 <br>\n",
    "例:C和弦onset的位置為[0, 4, 7] <br>\n",
    "則拿出lookup table位置為[0,4,7]的三個row\n",
    "然後把3個row加總起來變成一個1X1024維度的陣列當做C和弦的Embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loads the embeddings variable from the tensorflow checkpoint\n",
    "def load_embeddings(checkpoint_path):\n",
    "    with tf.Session() as session:\n",
    "        if checkpoint_path:\n",
    "            saver = tf.train.import_meta_graph(checkpoint_path+'/linear_D1024.ckpt-164.meta')\n",
    "            saver.restore(session, tf.train.latest_checkpoint(checkpoint_path))\n",
    "          \n",
    "            return session.run('embedding:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from save_models/linear\\linear_D1024.ckpt-6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.885763</td>\n",
       "      <td>-0.698374</td>\n",
       "      <td>-0.985356</td>\n",
       "      <td>-0.168804</td>\n",
       "      <td>-1.462866</td>\n",
       "      <td>-1.173522</td>\n",
       "      <td>0.771879</td>\n",
       "      <td>0.330421</td>\n",
       "      <td>0.843977</td>\n",
       "      <td>0.709352</td>\n",
       "      <td>...</td>\n",
       "      <td>0.765034</td>\n",
       "      <td>0.081080</td>\n",
       "      <td>-0.951852</td>\n",
       "      <td>-1.100772</td>\n",
       "      <td>0.257062</td>\n",
       "      <td>1.653568</td>\n",
       "      <td>1.865348</td>\n",
       "      <td>-0.297716</td>\n",
       "      <td>-0.945742</td>\n",
       "      <td>2.476066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.564719</td>\n",
       "      <td>-0.497007</td>\n",
       "      <td>-1.393687</td>\n",
       "      <td>-0.728143</td>\n",
       "      <td>-0.716429</td>\n",
       "      <td>-2.432258</td>\n",
       "      <td>-1.967033</td>\n",
       "      <td>0.184841</td>\n",
       "      <td>1.747492</td>\n",
       "      <td>-0.963003</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.602678</td>\n",
       "      <td>0.996899</td>\n",
       "      <td>-0.049030</td>\n",
       "      <td>-2.182903</td>\n",
       "      <td>-0.445242</td>\n",
       "      <td>0.466168</td>\n",
       "      <td>1.033728</td>\n",
       "      <td>0.939471</td>\n",
       "      <td>0.534260</td>\n",
       "      <td>1.432744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.147131</td>\n",
       "      <td>0.338825</td>\n",
       "      <td>0.190830</td>\n",
       "      <td>-0.465612</td>\n",
       "      <td>0.293960</td>\n",
       "      <td>0.851809</td>\n",
       "      <td>0.926844</td>\n",
       "      <td>0.542515</td>\n",
       "      <td>-0.390931</td>\n",
       "      <td>1.758892</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.351451</td>\n",
       "      <td>-0.998305</td>\n",
       "      <td>-0.953686</td>\n",
       "      <td>1.127539</td>\n",
       "      <td>0.822034</td>\n",
       "      <td>-0.498805</td>\n",
       "      <td>-1.194230</td>\n",
       "      <td>-0.379888</td>\n",
       "      <td>-0.332850</td>\n",
       "      <td>-1.293034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.448611</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>-0.106104</td>\n",
       "      <td>-1.350085</td>\n",
       "      <td>-1.208089</td>\n",
       "      <td>-0.686389</td>\n",
       "      <td>0.676287</td>\n",
       "      <td>0.910190</td>\n",
       "      <td>1.533031</td>\n",
       "      <td>-0.017758</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.125893</td>\n",
       "      <td>1.198886</td>\n",
       "      <td>-0.058276</td>\n",
       "      <td>-2.070835</td>\n",
       "      <td>0.557820</td>\n",
       "      <td>-1.547150</td>\n",
       "      <td>-0.506189</td>\n",
       "      <td>-0.566411</td>\n",
       "      <td>0.090274</td>\n",
       "      <td>-1.076528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.008666</td>\n",
       "      <td>0.746809</td>\n",
       "      <td>-1.696258</td>\n",
       "      <td>1.211193</td>\n",
       "      <td>-1.171438</td>\n",
       "      <td>0.216586</td>\n",
       "      <td>-0.923916</td>\n",
       "      <td>0.035863</td>\n",
       "      <td>0.850063</td>\n",
       "      <td>-0.356309</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.676470</td>\n",
       "      <td>-1.356658</td>\n",
       "      <td>3.318455</td>\n",
       "      <td>-0.204378</td>\n",
       "      <td>2.091613</td>\n",
       "      <td>0.429440</td>\n",
       "      <td>0.789041</td>\n",
       "      <td>-1.254088</td>\n",
       "      <td>-0.519818</td>\n",
       "      <td>1.526186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -0.885763 -0.698374 -0.985356 -0.168804 -1.462866 -1.173522  0.771879   \n",
       "1 -0.564719 -0.497007 -1.393687 -0.728143 -0.716429 -2.432258 -1.967033   \n",
       "2 -1.147131  0.338825  0.190830 -0.465612  0.293960  0.851809  0.926844   \n",
       "3 -0.448611  0.408163 -0.106104 -1.350085 -1.208089 -0.686389  0.676287   \n",
       "4 -1.008666  0.746809 -1.696258  1.211193 -1.171438  0.216586 -0.923916   \n",
       "\n",
       "       7         8         9       ...         1014      1015      1016  \\\n",
       "0  0.330421  0.843977  0.709352    ...     0.765034  0.081080 -0.951852   \n",
       "1  0.184841  1.747492 -0.963003    ...    -0.602678  0.996899 -0.049030   \n",
       "2  0.542515 -0.390931  1.758892    ...    -0.351451 -0.998305 -0.953686   \n",
       "3  0.910190  1.533031 -0.017758    ...    -0.125893  1.198886 -0.058276   \n",
       "4  0.035863  0.850063 -0.356309    ...    -0.676470 -1.356658  3.318455   \n",
       "\n",
       "       1017      1018      1019      1020      1021      1022      1023  \n",
       "0 -1.100772  0.257062  1.653568  1.865348 -0.297716 -0.945742  2.476066  \n",
       "1 -2.182903 -0.445242  0.466168  1.033728  0.939471  0.534260  1.432744  \n",
       "2  1.127539  0.822034 -0.498805 -1.194230 -0.379888 -0.332850 -1.293034  \n",
       "3 -2.070835  0.557820 -1.547150 -0.506189 -0.566411  0.090274 -1.076528  \n",
       "4 -0.204378  2.091613  0.429440  0.789041 -1.254088 -0.519818  1.526186  \n",
       "\n",
       "[5 rows x 1024 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_trained=load_embeddings('save_models/linear')\n",
    "pd.DataFrame(embeddings_trained).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1014</th>\n",
       "      <th>1015</th>\n",
       "      <th>1016</th>\n",
       "      <th>1017</th>\n",
       "      <th>1018</th>\n",
       "      <th>1019</th>\n",
       "      <th>1020</th>\n",
       "      <th>1021</th>\n",
       "      <th>1022</th>\n",
       "      <th>1023</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.475685</td>\n",
       "      <td>0.913832</td>\n",
       "      <td>-3.746457</td>\n",
       "      <td>1.352629</td>\n",
       "      <td>-1.555308</td>\n",
       "      <td>-1.950082</td>\n",
       "      <td>-0.153541</td>\n",
       "      <td>0.78741</td>\n",
       "      <td>0.735403</td>\n",
       "      <td>-0.927289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.100187</td>\n",
       "      <td>-1.417388</td>\n",
       "      <td>1.308784</td>\n",
       "      <td>-2.470891</td>\n",
       "      <td>1.78009</td>\n",
       "      <td>2.126603</td>\n",
       "      <td>1.601808</td>\n",
       "      <td>-2.80539</td>\n",
       "      <td>-2.189459</td>\n",
       "      <td>3.402207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 1024 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0 -2.475685  0.913832 -3.746457  1.352629 -1.555308 -1.950082 -0.153541   \n",
       "\n",
       "      7         8         9       ...         1014      1015      1016  \\\n",
       "0  0.78741  0.735403 -0.927289    ...    -0.100187 -1.417388  1.308784   \n",
       "\n",
       "       1017     1018      1019      1020     1021      1022      1023  \n",
       "0 -2.470891  1.78009  2.126603  1.601808 -2.80539 -2.189459  3.402207  \n",
       "\n",
       "[1 rows x 1024 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index=chord_vector.get('C:maj')\n",
    "Cmaj_Embedding=embeddings_trained[index].sum(axis=0).reshape(1, 1024)\n",
    "pd.DataFrame(Cmaj_Embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用pretained好的chord2vec表徵每首曲子的每個和弦\n",
    "C和弦是chord2vec lookup表的[0,4,7]rows的總和  <br>\n",
    "把每個和弦的vector總和算出來變成1X500並做出一張表，之後查這張表的和弦對應的row以找出一個和弦的vector總和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "chord_vector = {\n",
    "               \n",
    "        'C:maj':  [0,4,7],\n",
    "        'Db:maj': [1,5,8],\n",
    "        'Db:min': [1,4,8],\n",
    "        'D:maj':  [2,7,9],\n",
    "        'Eb:maj': [3,7,10],\n",
    "        'Eb:min': [3,6,10],\n",
    "        'E:maj':  [4,8,11],\n",
    "        'E:min':  [4,7,11],\n",
    "        'F:maj':  [0,5,9],\n",
    "        'F:min':  [0,4,9],\n",
    "        'Gb:maj': [1,6,10],\n",
    "        'Gb:min': [1,6,9],\n",
    "        'G:maj':  [2,7,11],\n",
    "        'G:min':  [2,7,10],\n",
    "        'Ab:maj': [0,3,8],\n",
    "        'Ab:min': [3,8,11],\n",
    "        'A:maj':  [1,4,9],\n",
    "        'A:min':  [0,4,9],\n",
    "        'Bb:maj': [2,5,10],\n",
    "        'Bb:min': [1,5,10],\n",
    "        'B:maj':  [2,6,11],\n",
    "        'B:min':  [1,6,11]    \n",
    "   \n",
    "    }\n",
    "chord_index={\n",
    "    'C:maj':  1,\n",
    "    'Db:maj': 2,\n",
    "    'Db:min': 3,\n",
    "    'D:maj':  4,\n",
    "    'Eb:maj': 5,\n",
    "    'Eb:min': 6,\n",
    "    'E:maj':  7,\n",
    "    'E:min':  8,\n",
    "    'F:maj':  9,\n",
    "    'F:min':  10,\n",
    "    'Gb:maj': 11,\n",
    "    'Gb:min': 12,\n",
    "    'G:maj':  13,\n",
    "    'G:min':  14,\n",
    "    'Ab:maj': 15,\n",
    "    'Ab:min': 16,\n",
    "    'A:maj':  17,\n",
    "    'A:min':  18,\n",
    "    'Bb:maj': 19,\n",
    "    'Bb:min': 20,\n",
    "    'B:maj':  21,\n",
    "    'B:min':  22    \n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./save_models/linear/0507\\linear_D1024.ckpt-164\n"
     ]
    }
   ],
   "source": [
    "embeddings_trained=load_embeddings('./save_models/linear/0507')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Chord_embedding_sum_lookup=np.array([])\n",
    "Chord_embedding_sum_lookup=np.append(Chord_embedding_sum_lookup,np.zeros(500))\n",
    "for chord in chord_vector:\n",
    "    index=chord_vector.get(chord)\n",
    "    chord_Embedding_sum=embeddings_trained[index].sum(axis=0).reshape(1, 500)\n",
    "    Chord_embedding_sum_lookup=np.append(Chord_embedding_sum_lookup,chord_Embedding_sum)\n",
    "Chord_embedding_sum_lookup=Chord_embedding_sum_lookup.reshape(23,500)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "out = open(\"../Question_Answering_Structure/QA_data/Chord_embedding_sum_lookup\",\"wb\")\n",
    "pickle.dump(Chord_embedding_sum_lookup, out)\n",
    "print('ok')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 208.666666,
   "position": {
    "height": "230px",
    "left": "743px",
    "right": "20px",
    "top": "-6px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "block",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
